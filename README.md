# NovaSight
Project Overview
NovaSight is an intelligent object detection system designed for space stations that identifies critical tools (toolboxes, oxygen tanks, fire extinguishers) using synthetic data from Duality AI's Falcon platform. Key innovations include:

Context-aware prioritization: Detection focus dynamically shifts based on environmental conditions (oxygen levels, temperature)

Self-improving feedback loop: Identifies weak performance areas (occlusion, lighting issues) and uses Falcon to generate improved synthetic data for retraining

AR Companion App: Lightweight augmented reality mobile application for real-time tool identification in emergencies or low visibility

Step-by-Step Instructions
1. Clone Repository
bash
git clone [https://github.com/yourusername/space-station-object-detection.git](https://github.com/harshithaps11/NovaSight.git)
cd NovaSight
2. Environment Setup
bash
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
3. Download Dataset
Place Falcon-generated synthetic dataset in data/ directory

Structure: images/ and labels/ folders

4. Train Model with Context-Aware Parameters
bash
python train.py --data data/dataset.yaml --context oxygen_level=0.85,temp=22
Context parameters adjust detection priorities during training

5. Run Inference with AR Companion App
bash
python ar_companion.py --weights runs/train/exp/weights/best.pt --source 0  # webcam
Displays real-time AR overlay with object prioritization

6. Start Feedback Loop
bash
python feedback_loop.py --results runs/val/ --falcon-api-key YOUR_KEY
Automatically generates new synthetic data for weak performance areas

Reproducing Final Results
Baseline Results:

bash
python val.py --data data/dataset.yaml --weights models/baseline.pt
Context-Aware Results:

bash
python val.py --data data/dataset.yaml --weights models/context_aware.pt --context oxygen_level=0.85
Feedback Loop Results:

bash
python val.py --data data/retrained_dataset.yaml --weights models/retrained.pt
Environment Requirements
Python: 3.10+

Core Dependencies:

ultralytics==8.0.0

torch==2.0.1

opencv-contrib-python==4.8.0

dualityai-falcon==1.2.0

AR Companion Dependencies:

pyarkit==0.5.3

flask==2.3.2

Expected Outputs
Detection Outputs
Output Type	Location	Interpretation
Bounding Boxes	runs/detect/	Objects annotated with class labels and confidence scores
Priority Heatmap	runs/priority/	Color-coded visualization of detection priorities
AR Overlay	Mobile screen	Real-time object identification with contextual alerts
Evaluation Metrics
Metric	Interpretation
Contextual mAP	Detection accuracy under specific environmental conditions
Priority Shift Efficiency	Time-to-detection for high-priority objects during simulated emergencies
Failure Case Reduction	Percentage improvement in previously weak scenarios after retraining
System Architecture
text
graph LR
A[Falcon Synthetic Data] --> B[YOLOv8 Training]
B --> C[Context-Aware Detection]
C --> D[AR Companion App]
D --> E[Performance Analysis]
E --> F[Failure Case Identification]
F --> A
Additional Features
Emergency Mode:

Trigger with --emergency flag to prioritize life-critical objects

Example: python detect.py --weights best.pt --source 0 --emergency fire

Self-Improvement Dashboard:

Run python dashboard.py to visualize:

Performance gaps before/after retraining

New synthetic data generated by Falcon

Contextual performance metrics

Zero-G Simulation Mode:

Test detection in simulated microgravity environments:

bash
python detect.py --weights best.pt --source data/zero_g_sim/ --simulate zero_g
Troubleshooting
AR App Connection Issues: Ensure mobile device and host are on same network

Falcon Data Generation: Verify API key in config/falcon.ini

Context Parameters: Supported contexts: oxygen_level (0.0-1.0), temp (Celsius), emergency (fire/breach/tool_loss)
